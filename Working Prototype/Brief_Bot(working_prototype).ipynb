{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Brief Bot"
      ],
      "metadata": {
        "id": "bowK2b8k-jx6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Required Dependencies\n"
      ],
      "metadata": {
        "id": "kG7yDPL3-VIp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kx69Xoj-Qlr",
        "outputId": "76f33b09-0e9f-4670-9569-efc7e8f006f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ibm-watsonx-ai in /usr/local/lib/python3.11/dist-packages (1.3.26)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2.32.4)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (0.28.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2.4.0)\n",
            "Requirement already satisfied: pandas<2.3.0,>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2025.6.15)\n",
            "Requirement already satisfied: lomond in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (0.3.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (24.2)\n",
            "Requirement already satisfied: ibm-cos-sdk<2.15.0,>=2.12.0 in /usr/local/lib/python3.11/dist-packages (from ibm-watsonx-ai) (2.14.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ibm-watsonx-ai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ibm-watsonx-ai) (0.16.0)\n",
            "Requirement already satisfied: ibm-cos-sdk-core==2.14.2 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai) (2.14.2)\n",
            "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.14.2 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai) (2.14.2)\n",
            "Requirement already satisfied: jmespath<=1.0.1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from ibm-cos-sdk-core==2.14.2->ibm-cos-sdk<2.15.0,>=2.12.0->ibm-watsonx-ai) (2.9.0.post0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=0.24.2->ibm-watsonx-ai) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ibm-watsonx-ai) (3.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from lomond->ibm-watsonx-ai) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->ibm-watsonx-ai) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->ibm-watsonx-ai) (4.14.0)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade ibm-watsonx-ai\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install ffmpeg-python"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## files upload"
      ],
      "metadata": {
        "id": "h2cfmQat-fun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"üìÅ Upload audio/video file (MP3, WAV, MP4, etc.)\")\n",
        "uploaded = files.upload()\n",
        "file_path = next(iter(uploaded))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "iNuboCMS-tAu",
        "outputId": "35e0793d-5b92-4b1f-f8ea-95c4e1991bb4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Upload audio/video file (MP3, WAV, MP4, etc.)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a6774a5a-8a8c-47d7-b2db-35ece6e171e6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a6774a5a-8a8c-47d7-b2db-35ece6e171e6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Screen Recording 2025-06-28 115332.mp4 to Screen Recording 2025-06-28 115332.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting to WAV/MP3 (if video)"
      ],
      "metadata": {
        "id": "k2qRLbUH-vX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import mimetypes\n",
        "import ffmpeg\n",
        "\n",
        "# auto-detect mimetype\n",
        "mimetype = mimetypes.guess_type(file_path)[0]\n",
        "base_name = os.path.splitext(file_path)[0]\n",
        "audio_path = f\"{base_name}.mp3\"\n",
        "\n",
        "if mimetype and mimetype.startswith(\"video\"):\n",
        "    print(\"üé• Converting video to audio...\")\n",
        "    ffmpeg.input(file_path).output(audio_path, format='mp3', acodec='libmp3lame').run(overwrite_output=True)\n",
        "else:\n",
        "    audio_path = file_path  # already audio\n"
      ],
      "metadata": {
        "id": "Nc3mO5Tg-2in",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da5ac151-dcc6-4603-f598-d2cf70a79ba4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé• Converting video to audio...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transcribe with Whisper"
      ],
      "metadata": {
        "id": "b-sSsr3b-48n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(audio_path)\n",
        "transcript = result[\"text\"]\n",
        "\n",
        "print(\"‚úÖ Transcript:\")\n",
        "print(transcript)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BDScLhC-9Wg",
        "outputId": "f64a0ec6-0ba9-4b13-e601-ddd46b45cdec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 139M/139M [00:01<00:00, 88.2MiB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Transcript:\n",
            " Good morning, team. Let's quickly review the deliverables from this sprint. First, John, please finalize the budget proposal and send it to the finance department by Friday. Priya, you'll handle the onboarding of the two new hires. Make sure their accounts and training plans are ready before Monday. Also, the client feedback on the dashboard UI has been mostly positive, but they did request faster load times. Garage, can you work with the back end team to optimize the APIs this week? Let's aim to complete the demo recording for the investor pitch by Thursday. All right, that wraps up the key points. Any questions?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Call IBM Granite for Summary"
      ],
      "metadata": {
        "id": "IMsLuFcz--wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Use your actual API key and project ID here\n",
        "API_KEY = \"*****************************\"\n",
        "PROJECT_ID = \"*******************************\"\n",
        "REGION = \"us-south\""
      ],
      "metadata": {
        "id": "8Vt5n24O_ISB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ibm_watsonx_ai.foundation_models import Model\n",
        "from ibm_watsonx_ai import Credentials\n",
        "import re\n",
        "\n",
        "credentials = Credentials(\n",
        "    api_key=API_KEY,\n",
        "    url=f\"https://{REGION}.ml.cloud.ibm.com\"\n",
        ")\n",
        "\n",
        "model = Model(\n",
        "    model_id=\"ibm/granite-3-3-8b-instruct\",\n",
        "    credentials=credentials,\n",
        "    project_id=PROJECT_ID,\n",
        "    params={\n",
        "        \"decoding_method\": \"greedy\",\n",
        "        \"max_new_tokens\": 300,\n",
        "        \"stop_sequences\": [\"</response>\"]\n",
        "    }\n",
        ")\n",
        "\n",
        "prompt = f\"\"\"\n",
        "<think>\n",
        "You are a smart assistant. Given this meeting transcript, summarize the key points and action items with deadlines and owners.\n",
        "\n",
        "Transcript:\n",
        "{transcript}\n",
        "</think>\n",
        "<response>\n",
        "\"\"\"\n",
        "\n",
        "summary = model.generate_text(prompt)\n",
        "cleaned = re.sub(r\"[*#]+\", \"\", summary)\n",
        "cleaned = re.sub(r\"\\n{2,}\", \"\\n\", cleaned)\n",
        "print(\"üìã Summary:\\n\", cleaned.strip())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT_fl4_H--dQ",
        "outputId": "62fe8b01-ee97-4f4e-8d1b-6b9924cf96ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ibm_watsonx_ai/foundation_models/model.py:105: DeprecationWarning: The `Model` class is deprecated and will be removed in a future release. Please use the `ModelInference` class instead. To update your imports, use: `from ibm_watsonx_ai.foundation_models import ModelInference`.\n",
            "  warn(model_class_deprecated_warning, category=DeprecationWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìã Summary:\n",
            " Key Points and Action Items:\n",
            "1. Budget Proposal:\n",
            "   - Owner: John\n",
            "   - Deadline: Friday\n",
            "   - Action: Finalize and send the budget proposal to the finance department.\n",
            "2. New Hire Onboarding:\n",
            "   - Owner: Priya\n",
            "   - Deadline: Before Monday\n",
            "   - Action: Ensure new hires' accounts and training plans are ready.\n",
            "3. Dashboard UI Feedback:\n",
            "   - Status: Client feedback is mostly positive, but they requested faster load times.\n",
            "   - Action: Address the request for improved load times.\n",
            "4. API Optimization:\n",
            "   - Owner: Garage (in collaboration with the back-end team)\n",
            "   - Deadline: This week\n",
            "   - Action: Work on optimizing the APIs to enhance load times.\n",
            "5. Investor Pitch Demo Recording:\n",
            "   - Deadline: Thursday\n",
            "   - Action: Complete the demo recording for the investor pitch.\n",
            " Summary:\n",
            "The meeting focused on finalizing deliverables from the current sprint. John is tasked with finalizing the budget proposal by Friday. Priya is responsible for preparing the onboarding of two new hires, ensuring their accounts and training plans are ready by Monday. The team noted positive client feedback on the dashboard UI but requested faster load times, which Garage will address by optimizing APIs this week.\n"
          ]
        }
      ]
    }
  ]
}